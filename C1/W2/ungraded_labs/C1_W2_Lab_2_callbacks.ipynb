{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"colab":{"collapsed_sections":[],"name":"C1_W2_Lab_2_callbacks.ipynb","private_outputs":true,"provenance":[{"file_id":"https://github.com/https-deeplearning-ai/tensorflow-1-public/blob/adding_C1/C1/W2/ungraded_labs/C1_W2_Lab_2_callbacks.ipynb","timestamp":1638884482962}],"toc_visible":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Ungraded Lab: Using Callbacks to Control Training 使用回调控制训练\n\nIn this lab, you will use the [Callbacks API](https://keras.io/api/callbacks/) to stop training when a specified metric is met. This is a useful feature so you won't need to complete all epochs when this threshold is reached. For example, if you set 1000 epochs and your desired accuracy is already reached at epoch 200, then the training will automatically stop. Let's see how this is implemented in the next sections.\n\n在本实验中，你将使用 Callbacks API 在达到指定指标时停止训练。这是一个非常有用的功能，因为当达到阈值时，你无需完成所有的训练轮数（epochs）。例如，如果你设置了 1000 个 epochs，但你的目标准确率已经在第 200 个 epoch 达到了，那么训练将自动停止。让我们在接下来的部分中看看如何实现这一点。","metadata":{"id":"vBNo9JrZIYG6"}},{"cell_type":"markdown","source":"## Load and Normalize the Fashion MNIST dataset 加载并归一化 Fashion MNIST 数据集\n\nLike the previous lab, you will use the Fashion MNIST dataset again for this exercise. And also as mentioned before, you will normalize the pixel values to help optimize the training.\n\n与之前的实验一样，你将再次使用 Fashion MNIST 数据集来完成本练习。同时，如前所述，你将归一化像素值以帮助优化训练过程。","metadata":{"id":"Mcwrn9AKKVb8"}},{"cell_type":"code","source":"#I use kaggle as the notebook, which will load the dataset as below\nimport tensorflow as tf\nimport numpy as np\nimport kagglehub\n\ndef load_images(file_path):\n    with open(file_path, 'rb') as f:\n        data = np.frombuffer(f.read(), dtype=np.uint8, offset=16)\n    return data.reshape(-1, 28, 28)\n\ndef load_labels(file_path):\n    with open(file_path, 'rb') as f:\n        data = np.frombuffer(f.read(), dtype=np.uint8, offset=8)\n    return data\n\npath = kagglehub.dataset_download(\"zalando-research/fashionmnist\")\n\ntraining_images_path = path + '/train-images-idx3-ubyte'  \ntraining_labels_path = path + '/train-labels-idx1-ubyte'\ntesting_images_path = path + '/t10k-images-idx3-ubyte'\ntesting_labels_path = path + '/t10k-labels-idx1-ubyte'\n\n# load data\nx_training = load_images(training_images_path)\ny_train = load_labels(training_labels_path)\nx_testing = load_images(testing_images_path)\ny_test = load_labels(testing_labels_path)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-27T20:41:43.774801Z","iopub.execute_input":"2025-01-27T20:41:43.775414Z","iopub.status.idle":"2025-01-27T20:41:44.224911Z","shell.execute_reply.started":"2025-01-27T20:41:43.775371Z","shell.execute_reply":"2025-01-27T20:41:44.223661Z"}},"outputs":[],"execution_count":4},{"cell_type":"code","source":"\n\n# Instantiate the dataset API\n# fmnist = tf.keras.datasets.fashion_mnist\n\n# Load the dataset\n# (x_train, y_train), (x_test, y_test) = fmnist.load_data()\n\n# Normalize the pixel values\nx_train, x_test = x_training / 255.0, x_testing / 255.0","metadata":{"id":"8LTaefqDJMIn","trusted":true,"execution":{"iopub.status.busy":"2025-01-27T20:41:46.719019Z","iopub.execute_input":"2025-01-27T20:41:46.719419Z","iopub.status.idle":"2025-01-27T20:41:46.970829Z","shell.execute_reply.started":"2025-01-27T20:41:46.719390Z","shell.execute_reply":"2025-01-27T20:41:46.969645Z"}},"outputs":[],"execution_count":5},{"cell_type":"markdown","source":"## Creating a Callback class 创建回调类\n\nYou can create a callback by defining a class that inherits the [tf.keras.callbacks.Callback](https://www.tensorflow.org/api_docs/python/tf/keras/callbacks/Callback) base class. From there, you can define available methods to set where the callback will be executed. For instance below, you will use the [on_epoch_end()](https://www.tensorflow.org/api_docs/python/tf/keras/callbacks/Callback#on_epoch_end) method to check the loss at each training epoch.\n\n你可以通过定义一个继承 tf.keras.callbacks.Callback 基类的类来创建回调。然后，你可以定义可用的方法来设置回调在何时执行。例如，在下面的代码中，你将使用 on_epoch_end() 方法在每个训练 epoch 结束时检查损失值。","metadata":{"id":"Ia2OadhALJjS"}},{"cell_type":"code","source":"class myCallback(tf.keras.callbacks.Callback):\n    def on_epoch_end(self, epoch, logs=None):\n        '''\n        Halts the training when the loss falls below 0.4\n\n        Args:\n            epoch (integer) - index of epoch (required but unused in the function definition below)\n            logs (dict) - metric results from the training epoch\n        '''\n\n        # Check the loss\n        if logs['loss'] < 0.4:\n\n            # Stop if threshold is met\n            print(\"\\nLoss is lower than 0.4 so cancelling training!\")\n            self.model.stop_training = True","metadata":{"id":"uuRmQZWVJAJH","trusted":true,"execution":{"iopub.status.busy":"2025-01-27T20:41:49.885975Z","iopub.execute_input":"2025-01-27T20:41:49.886444Z","iopub.status.idle":"2025-01-27T20:41:49.893027Z","shell.execute_reply.started":"2025-01-27T20:41:49.886416Z","shell.execute_reply":"2025-01-27T20:41:49.891531Z"}},"outputs":[],"execution_count":6},{"cell_type":"markdown","source":"## Define and compile the model 定义并编译模型\n\nNext, you will define and compile the model. The architecture will be similar to the one you built in the previous lab. Afterwards, you will set the optimizer, loss, and metrics that you will use for training.\n\n接下来，你将定义并编译模型。模型的结构将与你之前实验中构建的类似。之后，你将设置用于训练的优化器、损失函数和评估指标。","metadata":{"id":"4xlXeLkFeMn8"}},{"cell_type":"code","source":"# Define the model\nmodel = tf.keras.models.Sequential([\n    tf.keras.Input(shape=(28,28)),\n    tf.keras.layers.Flatten(),\n    tf.keras.layers.Dense(512, activation=tf.nn.relu),\n    tf.keras.layers.Dense(10, activation=tf.nn.softmax)\n])\n\n# Compile the model\nmodel.compile(optimizer=tf.optimizers.Adam(),\n              loss='sparse_categorical_crossentropy',\n              metrics=['accuracy'])","metadata":{"id":"7JXxMg3TpzER","trusted":true,"execution":{"iopub.status.busy":"2025-01-27T20:41:56.318141Z","iopub.execute_input":"2025-01-27T20:41:56.318569Z","iopub.status.idle":"2025-01-27T20:41:56.430896Z","shell.execute_reply.started":"2025-01-27T20:41:56.318539Z","shell.execute_reply":"2025-01-27T20:41:56.429643Z"}},"outputs":[],"execution_count":7},{"cell_type":"markdown","source":"### Train the model 训练模型\n\nNow you are ready to train the model. To set the callback, simply set the `callbacks` parameter to an instance of `myCallback` put into a list. Run the cell below and observe what happens.\n\n现在你已经准备好训练模型了。要设置回调，只需将 callbacks 参数设置为 myCallback 的实例，并将其放入一个列表中。运行下面的单元格并观察会发生什么。","metadata":{"id":"6eLe4cPZe-ui"}},{"cell_type":"code","source":"# Train the model with a callback\nmodel.fit(x_train, y_train, epochs=10, callbacks=[myCallback()])","metadata":{"id":"nLXTB32de3_e","trusted":true,"execution":{"iopub.status.busy":"2025-01-27T20:41:59.646565Z","iopub.execute_input":"2025-01-27T20:41:59.647009Z","iopub.status.idle":"2025-01-27T20:42:25.116604Z","shell.execute_reply.started":"2025-01-27T20:41:59.646977Z","shell.execute_reply":"2025-01-27T20:42:25.115128Z"}},"outputs":[{"name":"stdout","text":"Epoch 1/10\n\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 6ms/step - accuracy: 0.7942 - loss: 0.5781\nEpoch 2/10\n\u001b[1m1869/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8691 - loss: 0.3621\nLoss is lower than 0.4 so cancelling training!\n\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 6ms/step - accuracy: 0.8691 - loss: 0.3621\n","output_type":"stream"},{"execution_count":8,"output_type":"execute_result","data":{"text/plain":"<keras.src.callbacks.history.History at 0x7d63e0474340>"},"metadata":{}}],"execution_count":8},{"cell_type":"markdown","source":"You will notice that the training does not need to complete all 10 epochs. By having a callback at the end of each epoch, it is able to check the training parameters and compare if it meets the threshold you set in the function definition. In this case, it will simply stop when the loss falls below `0.40` after the current epoch.\n\n*Optional Challenge: Modify the code to make the training stop when the accuracy metric exceeds 60%.*\n\nThat concludes this simple exercise on callbacks!\n\n你会注意到，训练不需要完成所有的 10 个 epochs。通过在每个 epoch 结束时设置回调，它能够检查训练参数，并判断是否满足你在函数定义中设置的阈值。在这个例子中，当损失值在当前 epoch 结束后低于 0.40 时，训练将自动停止。\n\n可选挑战：修改代码，使训练在准确率超过 60% 时停止。\n\n这就是关于回调的简单练习的全部内容！","metadata":{"id":"fGBSkRQPff93"}}]}